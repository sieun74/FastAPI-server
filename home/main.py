from fastapi import FastAPI, UploadFile, File,WebSocket, WebSocketDisconnect
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware
from PIL import Image
from transformers import CLIPProcessor, CLIPModel
import torch
import io
import httpx
import traceback

app = FastAPI()

# CORS í—ˆìš© ì„¤ì • (í•„ìš”ì— ë”°ë¼ ë„ë©”ì¸ ë³€ê²½ ê°€ëŠ¥)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ì˜ˆ: ["http://localhost:3000"]
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# CLIP ëª¨ë¸ ë° í”„ë¡œì„¸ì„œ ë¡œë“œ (ìµœì´ˆ 1íšŒë§Œ ì¸í„°ë„· ì—°ê²° í•„ìš”)
model = CLIPModel.from_pretrained("openai/clip-vit-base-patch32")
processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch32")

import traceback

@app.post("/image/walk")
async def check_walk_mission(file: UploadFile = File(...)):
    try:
        candidate_texts = ["ì‚¬ëŒì´", "ë¬´ê´€í•œ ì‚¬ì§„"]
        image_bytes = await file.read()
        print(f"[walk] ì´ë¯¸ì§€ ë°”ì´íŠ¸ í¬ê¸°: {len(image_bytes)}")
        
        image = Image.open(io.BytesIO(image_bytes)).convert("RGB")
        print("[walk] ì´ë¯¸ì§€ ë¡œë“œ ì„±ê³µ")

        inputs = processor(text=candidate_texts, images=image, return_tensors="pt", padding=True)
        outputs = model(**inputs)
        probs = outputs.logits_per_image.softmax(dim=1)

        top_idx = torch.argmax(probs).item()
        top_text = candidate_texts[top_idx]
        passed = "ì„±ê³µ" if top_text == "ì‚°ì±… ì‚¬ì§„" else "ì‹¤íŒ¨"
        print(f"[walk] íŒë‹¨ ê²°ê³¼: {passed}")

        return JSONResponse(content={"mission_passed": passed})

    except Exception as e:
        print("[walk] ì—ëŸ¬ ë°œìƒ:", e)
        traceback.print_exc()
        return JSONResponse(content={"error": str(e)}, status_code=500)


@app.post("/image/nature")
async def check_nature_mission(file: UploadFile = File(...)):
    try:
        candidate_texts = ["ìì—°ë¬¼ ì‚¬ì§„", "ë¬´ê´€í•œ ì‚¬ì§„"]
        image_bytes = await file.read()
        print(f"[nature] ì´ë¯¸ì§€ ë°”ì´íŠ¸ í¬ê¸°: {len(image_bytes)}")
        
        image = Image.open(io.BytesIO(image_bytes)).convert("RGB")
        print("[nature] ì´ë¯¸ì§€ ë¡œë“œ ì„±ê³µ")

        inputs = processor(text=candidate_texts, images=image, return_tensors="pt", padding=True)
        outputs = model(**inputs)
        probs = outputs.logits_per_image.softmax(dim=1)

        top_idx = torch.argmax(probs).item()
        top_text = candidate_texts[top_idx]
        passed = "ì„±ê³µ" if top_text == "ìì—°ë¬¼ ì‚¬ì§„" else "ì‹¤íŒ¨"
        print(f"[nature] íŒë‹¨ ê²°ê³¼: {passed}")

        return JSONResponse(content={"mission_passed": passed})

    except Exception as e:
        print("[nature] ì—ëŸ¬ ë°œìƒ:", e)
        traceback.print_exc()
        return JSONResponse(content={"error": str(e)}, status_code=500)

GROQ_API_KEY = 'grop_your_API'
GROQ_API_URL = "https://api.groq.com/openai/v1/chat/completions"
GROQ_MODEL = "llama3-70b-8192"

# ìµœëŒ€ ëŒ€í™” ì €ì¥ ìˆ˜
MAX_HISTORY = 10

@app.websocket("/ws")
async def chat_with_groq(websocket: WebSocket):
    await websocket.accept()

    conversation = [
        {"role": "system", "content": "ë‹¹ì‹ ì€ í•œêµ­ì–´ë¥¼ ì˜í•˜ëŠ” ì¹œì ˆí•œ AI ì±—ë´‡ì…ë‹ˆë‹¤. ì§ˆë¬¸ì— ì •í™•í•˜ê²Œ ë‹µí•´ì£¼ì„¸ìš”."}
    ]

    try:
        async with httpx.AsyncClient() as client:
            while True:
                user_input = await websocket.receive_text()
                conversation.append({"role": "user", "content": user_input})

                # ìµœê·¼ ëŒ€í™”ë§Œ ìœ ì§€
                conversation = conversation[-MAX_HISTORY:]

                # Groq API í˜¸ì¶œ
                response = await client.post(
                    GROQ_API_URL,
                    headers={
                        "Authorization": f"Bearer {GROQ_API_KEY}",
                        "Content-Type": "application/json"
                    },
                    json={
                        "model": GROQ_MODEL,
                        "messages": conversation
                    },
                    timeout=30.0
                )

                if response.status_code != 200:
                    await websocket.send_text(f"âŒ Groq API í˜¸ì¶œ ì‹¤íŒ¨: {response.text}")
                    continue

                result = response.json()
                reply = result["choices"][0]["message"]["content"]
                conversation.append({"role": "assistant", "content": reply})

                await websocket.send_text(reply)

    except WebSocketDisconnect:
        print("ğŸ”Œ í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ì¢…ë£Œ")
    except Exception as e:
        print("âŒ ì—ëŸ¬ ë°œìƒ:", e)
        traceback.print_exc()
        await websocket.send_text("âŒ ì„œë²„ì—ì„œ ì—ëŸ¬ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
